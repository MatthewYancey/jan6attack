{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewYancey/Capitol_Faces/blob/main/src/facial_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlaiqTmJkTdb"
      },
      "source": [
        "# Facial Embeddings\n",
        "This notebook loops through the all videos, finds the distinct faces in each video and creates embeddings/encodings for the faces."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install face_recognition\n",
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "id": "7ao1SqBmxlMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HQ96aNvj_d4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import sys\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm import tnrange, tqdm_notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "sys.path.append('/content/gdrive/MyDrive/repos/Capitol_Faces/src')\n",
        "import helpers.general as gen\n",
        "import helpers.detection_and_clustering as dc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-fN-_9syRZU_"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "data_path = '/content/gdrive/MyDrive/repos/Capitol_Faces/data/'\n",
        "face_min_size = 80\n",
        "clustering_threshold = 0.5\n",
        "get_vid_length = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generates the list of vidoes to process"
      ],
      "metadata": {
        "id": "RpJ_Rv0vKAx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gets the selected videos\n",
        "top_n = 100\n",
        "df_meta = pd.read_csv(data_path + 'df_jan6attack_individuals.csv')\n",
        "df_meta = df_meta.loc[df_meta['date']=='2021-01-06', :]\n",
        "\n",
        "# gets the top n commonly sighted individuals in photos\n",
        "vid_list = df_meta.groupby('id')['video'].count().reset_index()\n",
        "vid_list = vid_list.sort_values('video', ascending=False).reset_index(drop=True)\n",
        "vid_list = vid_list.loc[:top_n, 'id'].to_list()\n",
        "vid_list = df_meta.loc[df_meta['id'].isin(vid_list), 'video'].to_list()\n",
        "vid_list = list(set(vid_list))\n",
        "vid_list = [os.path.basename(v[:-1]) for v in vid_list]\n",
        "print(f'Number of videos: {len(vid_list)}')"
      ],
      "metadata": {
        "id": "qE3lHSllw4k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loads metadata"
      ],
      "metadata": {
        "id": "4qPOzaqCTCWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads the video data frame and the faces data frame\n",
        "df_video_meta = pd.read_csv(data_path + 'df_video_meta.csv')\n",
        "\n",
        "# checks if we have the videos we need to process\n",
        "missing_videos = [v for v in vid_list if v not in df_video_meta['vid_id'].to_list()]\n",
        "print(f'Number of missing videos: {len(missing_videos)}')\n",
        "\n",
        "print(f'Number of videos already processed: {df_video_meta.loc[df_video_meta[\"vid_id\"].isin(vid_list) & df_video_meta[\"face_detection\"] == 1, :].shape[0]}')\n",
        "\n",
        "# vid_list = df_video_meta.loc[df_video_meta[\"face_detection\"] == 0, 'vid_id'].to_list()\n",
        "vid_list = df_video_meta.loc[(df_video_meta[\"vid_id\"].isin(vid_list)) & (df_video_meta[\"face_detection\"] == 0), 'vid_id'].to_list()\n",
        "print(f'Number of videos to be processed: {len(vid_list)}')\n",
        "\n",
        "# how many minutes of video do we have to process?\n",
        "if get_vid_length:\n",
        "    gen.get_video_summary(vid_list, data_path)"
      ],
      "metadata": {
        "id": "OnwIFqo6Kiwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkmwF7bT_Hlp"
      },
      "outputs": [],
      "source": [
        "df_faces = pd.read_csv(data_path + 'df_faces.csv')\n",
        "column_names = df_faces.columns\n",
        "\n",
        "# loops through the vids and gets the unique face\n",
        "for i in tnrange(len(vid_list)):\n",
        "    \n",
        "    print(f'Finding faces in {vid_list[i]}')\n",
        "    cap = cv2.VideoCapture(data_path + 'video/' + vid_list[i] + '.mp4')    \n",
        "    if cap.isOpened():\n",
        "\n",
        "        # gets all the faces and encodings from the video\n",
        "        vid_faces = dc.detect_faces(cap, vid_list[i], data_path, min_size=face_min_size)\n",
        "\n",
        "        # if we found any faces\n",
        "        if len(vid_faces) > 0:\n",
        "            # clusters the faces\n",
        "            df_faces_vid = pd.DataFrame(vid_faces, columns=['vid_id', 'frame', 'position'] + [f'encoding_{e}' for e in list(range(128))])\n",
        "            df_faces_vid = dc.cluster_faces(df_faces_vid, clustering_threshold)\n",
        "\n",
        "            # get the faces at the center of each cluster\n",
        "            df_faces_vid = dc.get_cluster_center(df_faces_vid)\n",
        "\n",
        "            # add the new faces to the face dataframe\n",
        "            df_faces_vid.drop('cluster', axis=1, inplace=True)\n",
        "            next_id = max(df_faces['id']) + 1\n",
        "            df_faces_vid['id'] = range(next_id, next_id + df_faces_vid.shape[0])\n",
        "            df_faces_vid = df_faces_vid.loc[:, ['id'] + list(df_faces_vid.columns[:-1])]\n",
        "            df_faces = df_faces.append(df_faces_vid)\n",
        "            df_faces.to_csv(data_path + 'df_faces.csv', index=False)\n",
        "\n",
        "        # updates the metadata that this video has been processed\n",
        "        df_video_meta.loc[df_video_meta['vid_id'] == vid_list[i], 'face_detection'] = 1\n",
        "        df_video_meta.to_csv(data_path + 'df_video_meta.csv', index=False)\n",
        "\n",
        "    else:\n",
        "        print(f'Bad path to video {vid_list[i]}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "facial_embeddings.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMK5x34Rcoa4pv5GPWJPS5X",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}